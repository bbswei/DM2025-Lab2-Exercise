{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbswei/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZeu42OX6mp4"
      },
      "source": [
        "### **Student Information**\n",
        "Name: ÁéãÂ¶§ÁëÑ\n",
        "\n",
        "Student ID: 110102042\n",
        "\n",
        "GitHub ID: bbswei\n",
        "\n",
        "Kaggle name: bbswei(Team name), akemiii(Account name)\n",
        "\n",
        "Kaggle private scoreboard snapshot:\n",
        "\n",
        "![pic_ranking.png](https://drive.google.com/uc?export=view&id=17Xez_aTXTGjiAiu1tSr9hvrh2sxh2vdE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc63hieb6mp5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EOzqo4O6mp6"
      },
      "source": [
        "# **Instructions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCYfCi_H6mp6"
      },
      "source": [
        "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
        "\n",
        "**Environment recommendations to solve lab 2:**\n",
        "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
        "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
        "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
        "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models.\n",
        "\n",
        "## **Phase 1 (30 pts):**\n",
        "\n",
        "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
        "\n",
        "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**.\n",
        "\n",
        "## **Phase 2 (30 pts):**\n",
        "\n",
        "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
        "\n",
        "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**.\n",
        "\n",
        "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
        "\n",
        "## **Phase 3 (40 pts):**\n",
        "\n",
        "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking:\n",
        "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
        "\n",
        "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
        "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
        "\n",
        "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements:\n",
        "* Your preprocessing steps.\n",
        "* The feature engineering steps.\n",
        "* Explanation of your model.\n",
        "\n",
        "* **`Bonus (5 pts):`**\n",
        "    * You will have to describe more detail in the previous steps.\n",
        "    * Mention different things you tried.\n",
        "    * Mention insights you gained.\n",
        "\n",
        "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
        "\n",
        "**`Things to note for Phase 3:`**\n",
        "\n",
        "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
        "\n",
        "* **Push the code used for the competition to your repository**.\n",
        "\n",
        "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
        "\n",
        "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
        "\n",
        "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
        "\n",
        "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IApYwKqM6mp7"
      },
      "source": [
        "**`From here on starts the code section for the competition.`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSjSowzu6mp8"
      },
      "source": [
        "# **Competition Code**\n",
        "\n",
        "## 1. Preprocessing Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_N2sIuel6mp8"
      },
      "outputs": [],
      "source": [
        "!pip install emoji torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Cnv6NaXaCJa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCnGRQpW6mp9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import emoji\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, DebertaV2Tokenizer, DebertaV2ForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7rMvdrb6mp9"
      },
      "source": [
        "### Load Merged Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21OYvLSc6mp9"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./train_processed.csv\")\n",
        "test_df = pd.read_csv(\"./test_processed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes are highly imbalanced"
      ],
      "metadata": {
        "id": "6Wqpaj5eCfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0gfxYiG6mp9"
      },
      "outputs": [],
      "source": [
        "print(train_df['emotion'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO31ekSG6mp-"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBPC8VW96mp-"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['emotion'])\n",
        "num_labels = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "print(f\"\\nnumber of labels: {num_labels}\\nclass names: {class_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F-pa3ty6mp-"
      },
      "source": [
        "### Text Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My preprocessing strategy was designed to maximize the retention of emotional signals while standardizing non-critical information into special tokens recognizable by RoBERTa."
      ],
      "metadata": {
        "id": "BPQIH5pRoERd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specific Steps:\n",
        "\n",
        "- URL Standardization: Any URL (http://... or www....) was replaced with a single special token: <URL>.\n",
        "\n",
        "- Mentions Standardization: Any user mention (@user) was replaced with a single special token: <USER>.\n",
        "\n",
        "- Emoji Conversion: Emojis (e.g., üòÇ) were converted into their standard text description (e.g., :face_with_tears_of_joy:). This allows the Tokenizer to treat emotional symbols as explicit word inputs rather than ignoring them or treating them as unknown characters."
      ],
      "metadata": {
        "id": "e7a1ZjuAoKWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_S7n-l-6mp-"
      },
      "outputs": [],
      "source": [
        "def clean_text(text: str) -> str:\n",
        "\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"@\\w+\", \" <USER> \", text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \" <URL> \", text)\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzWpzc_G6mp-"
      },
      "outputs": [],
      "source": [
        "train_df['text'] = train_df['text'].apply(clean_text)\n",
        "test_df['text'] = test_df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2v3f6e16mp-"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt7h6Me-6mp-"
      },
      "outputs": [],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAtwUoG6mp-"
      },
      "source": [
        "## 2. Feature Engineering Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T0fsEpn6mp-"
      },
      "source": [
        "### Class Imbalance Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the severe class imbalance in the emotion classification dataset (e.g., joy and sadness significantly outnumber fear and disgust), I designated mitigating class imbalance as the primary feature engineering step."
      ],
      "metadata": {
        "id": "wa7bsS62oVNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method: Inverse Class Frequency Weighting.\n",
        "\n",
        "First, I calculate the number of samples for each emotion class in the training set. The weight $W_i$ is calculated using the formula:\n",
        "\n",
        "$W_i = \\frac{\\text{Total Samples}}{\\text{Sample Count of Class } i}$.\n",
        "\n",
        "Finally, these weights are normalized and passed to PyTorch's nn.CrossEntropyLoss function as the weight parameter.\n",
        "\n",
        "Result: During loss calculation, sparse classes (like fear) receive a higher loss penalty, forcing the model to prioritize these difficult-to-predict samples, thereby directly optimizing the Macro F1-Score.\n",
        "\n"
      ],
      "metadata": {
        "id": "VYrsx81-oaIb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1NwQ5246mp_"
      },
      "outputs": [],
      "source": [
        "# Using Inversed Class Frequency to Calculate Class Weights\n",
        "class_counts = train_df['label'].value_counts().sort_index().values\n",
        "total_samples = class_counts.sum()\n",
        "\n",
        "class_weights = total_samples / class_counts\n",
        "class_weights = class_weights / class_weights.mean()\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "for i, weight in enumerate(class_weights):\n",
        "    print(f\"  Class [{class_names[i]}] -> Weight = {weight:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7dy4JHO6mp_"
      },
      "outputs": [],
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_df['text'],\n",
        "    train_df['label'],\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=train_df['label']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVVrjfgo6mp_"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shSjm3LQ6mp_"
      },
      "outputs": [],
      "source": [
        "# RoBERTa (Model 1) and DeBERTa (Model 2)\n",
        "ROBERTA_MODEL_NAME = 'roberta-large'\n",
        "DEBERTA_MODEL_NAME = 'microsoft/deberta-v3-base'\n",
        "\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_NAME)\n",
        "deberta_tokenizer = DebertaV2Tokenizer.from_pretrained(DEBERTA_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qw_E9f76mp_"
      },
      "outputs": [],
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, tokenizer=roberta_tokenizer, max_len=128):\n",
        "        self.texts = texts.to_list() if isinstance(texts, pd.Series) else texts\n",
        "        self.labels = labels.to_list() if isinstance(labels, pd.Series) else labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten()\n",
        "        }\n",
        "\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ë®ìÁ∑¥ RoBERTa\n",
        "train_dataloader = DataLoader(EmotionDataset(train_texts, train_labels, tokenizer=roberta_tokenizer), batch_size=16, shuffle=True)\n",
        "\n",
        "# RoBERTa È©óË≠âÈõÜ\n",
        "val_dataloader_roberta = DataLoader(EmotionDataset(val_texts, val_labels, tokenizer=roberta_tokenizer), batch_size=16)\n",
        "# DeBERTa È©óË≠âÈõÜ\n",
        "val_dataloader_deberta = DataLoader(EmotionDataset(val_texts, val_labels, tokenizer=deberta_tokenizer), batch_size=16)\n",
        "\n",
        "# RoBERTa Ê∏¨Ë©¶ÈõÜ\n",
        "test_dataloader_roberta = DataLoader(EmotionDataset(test_df['text'], tokenizer=roberta_tokenizer), batch_size=16)\n",
        "# DeBERTa Ê∏¨Ë©¶ÈõÜ\n",
        "test_dataloader_deberta = DataLoader(EmotionDataset(test_df['text'], tokenizer=deberta_tokenizer), batch_size=16)"
      ],
      "metadata": {
        "id": "9pDAK2NEC5_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JHG85zG6mp_"
      },
      "source": [
        "## 3. Model Implementation Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final solution uses an Ensemble of two fine-tuned models: RoBERTa-large and DeBERTa-v3-base, combined using Logit Averaging. The ensemble prediction then undergoes Threshold Tuning for final optimization.\n",
        "\n",
        "I experimented with two key post-processing techniques to maximize performance: **Test-Time Augmentation (TTA)** and **Logit Bias Optimization**. Since TTA did not yield a score improvement, only the Logit Bias Optimization technique was retained for the final submission.\n",
        "\n",
        "### **Test-Time Augmentation (TTA)**\n",
        "\n",
        "TTA involves creating 7 versions of the same tweet‚Äîthe original one and 6 copies that were slightly modified (e.g., random capitalization changes, or a few extra punctuation marks). The model made 7 sets of prediction scores (Logits), which were then averaged to get one very stable final score.\n",
        "\n",
        "I originally used TTA, but the score did not improve, so I did not continue with this.\n",
        "\n",
        "### **Logit Bias Optimization (Threshold Tuning)**\n",
        "\n",
        "Since emotions like 'Joy' and 'Sadness' appear much more often, the model tends to guess them frequently. This makes it difficult for the model to correctly predict rare emotions like 'Fear' or 'Disgust'.\n",
        "\n",
        "After the model provided the Ensemble-averaged scores, I applied bonus points (Logit Biases) to the scores of the rare classes (like 'Fear' or 'Disgust'). These Logit Biases were optimized on the validation set using a greedy search approach to maximize the Macro F1-Score."
      ],
      "metadata": {
        "id": "CIkCCkCzHDdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "class_weights = class_weights.to(device)"
      ],
      "metadata": {
        "id": "aHrl1_2BALqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've tried using 'roberta-base' before, but the scores stayed around 0.65‚Äì0.66, so I tried using 'roberta-large' and the score improved to 0.67. And because larger models require more training time and resources, my later attempts mainly focused on improving the evaluation/validation stage."
      ],
      "metadata": {
        "id": "bRrarMFzgPKz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "e2RCo5M16mp_"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'roberta-large' #roberta-base\n",
        "model = RobertaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN9J4c3b6mqA"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "EPOCHS = 5 #3 -> score: 0.6548"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add: Ë®àÁÆóÁ∏ΩÊ≠•Êï∏\n",
        "total_steps = len(train_dataloader) * EPOCHS"
      ],
      "metadata": {
        "id": "DBGMK4udA1xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I've tried different attempts:\n",
        "\n",
        "**Fixed Learning Rate (Initial Score $\\approx 0.65$)**: Initially trained with a fixed learning rate of $2e-5$ for 3 Epochs.\n",
        "\n",
        "\n",
        "**Introduction of Learning Rate Scheduler (Score $\\approx 0.6617$)**: Implemented the Warmup and Linear Decay Scheduler and increased training to 5 Epochs. This is the standard Fine-Tuning technique to ensure stable convergence and prevent weight oscillation."
      ],
      "metadata": {
        "id": "Kz_BMxp9o6gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(total_steps * 0.1), # add: ‰ΩøÁî®Á∏ΩÊ≠•Êï∏ÁöÑ 10% ‰ΩúÁÇ∫ Warmup\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "WlgVs3FnA6UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(weight=class_weights)"
      ],
      "metadata": {
        "id": "dcbdistDAU0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's output layer is a fully connected layer with $N$ classes (number of emotions), which outputs the probability of each class via the Softmax activation function."
      ],
      "metadata": {
        "id": "1r2em0b5oxXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "tq9SZRYkVzZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, data_loader, optimizer, criterion, device, scheduler, epoch_num, total_epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    data_iterator = tqdm(data_loader, desc=f\"Ë®ìÁ∑¥ Epoch {epoch_num}/{total_epochs}\", leave=True)\n",
        "\n",
        "    for batch in data_iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        data_iterator.set_postfix(loss=f\"{np.mean(losses):.4f}\")\n",
        "\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "WuFgr9ytEPLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device, description=\"È©óË≠â\"):\n",
        "    \"\"\"\n",
        "    ËøîÂõûÊâÄÊúâ Logits Âíå True LabelsÔºåÁî®ÊñºÂÅèÂ∑ÆÂÑ™Âåñ\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    data_iterator = tqdm(data_loader, desc=description, leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iterator:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            all_logits.append(outputs.logits.cpu())\n",
        "\n",
        "            if 'labels' in batch:\n",
        "                all_labels.append(batch['labels'].cpu())\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    if all_labels:\n",
        "        all_labels = torch.cat(all_labels, dim=0).numpy()\n",
        "\n",
        "        predictions = torch.argmax(all_logits, dim=1).numpy()\n",
        "        f1_macro = f1_score(all_labels, predictions, average='macro')\n",
        "        print(f\"\\n[{description} - Ê®ôÊ∫ñ Argmax] Macro F1-Score: {f1_macro:.4f}\")\n",
        "\n",
        "        return all_logits, all_labels\n",
        "\n",
        "    return all_logits, None"
      ],
      "metadata": {
        "id": "c663eJAaEjbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_thresholds(logits, true_labels, num_labels, threshold_steps=20):\n",
        "    \"\"\"\n",
        "    Âú®È©óË≠âÈõÜ‰∏äÊêúÂ∞ãÊúÄ‰Ω≥ Thresholds\n",
        "    \"\"\"\n",
        "    probabilities = torch.softmax(logits, dim=1).numpy()\n",
        "\n",
        "    best_f1 = -1.0\n",
        "    best_thresholds = np.zeros(num_labels)\n",
        "    threshold_range = np.linspace(0.01, 1.0, threshold_steps)\n",
        "    bias_range = np.linspace(-1.5, 1.5, 20)\n",
        "    best_biases = np.zeros(num_labels)\n",
        "\n",
        "    for class_idx in range(num_labels):\n",
        "        original_biases = best_biases.copy()\n",
        "\n",
        "        for bias in tqdm(bias_range, desc=f\"ÊêúÂ∞ã Class {class_names[class_idx]} ÊúÄ‰Ω≥ÂÅèÂ∑Æ\"):\n",
        "            current_biases = original_biases.copy()\n",
        "            current_biases[class_idx] = bias\n",
        "\n",
        "            # ÂÅèÂ∑ÆÊáâÁî®Âà∞ Logits ‰∏ä\n",
        "            biased_logits = logits.numpy() + current_biases\n",
        "\n",
        "            current_predictions = np.argmax(biased_logits, axis=1)\n",
        "            current_f1 = f1_score(true_labels, current_predictions, average='macro')\n",
        "\n",
        "            if current_f1 > best_f1:\n",
        "                best_f1 = current_f1\n",
        "                best_biases = current_biases.copy()\n",
        "\n",
        "        print(f\"  Class {class_names[class_idx]} ÊúÄ‰Ω≥ Logit Biases: {best_biases[class_idx]:.4f} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    print(f\"\\nÊúÄ‰Ω≥ Macro F1-Score: {best_f1:.4f}\")\n",
        "    print(f\"ÊúÄ‰Ω≥ Logit Biases: {best_biases}\")\n",
        "\n",
        "    return best_biases, best_f1"
      ],
      "metadata": {
        "id": "h1ATSz8q8dIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_thresholds(logits, biases):\n",
        "\n",
        "    biased_logits = logits.numpy() + biases\n",
        "    final_predictions = np.argmax(biased_logits, axis=1)\n",
        "\n",
        "    return final_predictions"
      ],
      "metadata": {
        "id": "M28vVW689PzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_model(model, data_loader, device, description=\"Model 2 Êé®Ë´ñ\"):\n",
        "    \"\"\"\n",
        "    Â∞çÁµ¶ÂÆöÁöÑ DataLoader Âü∑Ë°åÂñÆÊ¨°Êé®Ë´ñÔºåËøîÂõû Logits„ÄÇ\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "\n",
        "    data_iterator = tqdm(data_loader, desc=description, leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iterator:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            all_logits.append(outputs.logits.cpu())\n",
        "\n",
        "    return torch.cat(all_logits, dim=0)"
      ],
      "metadata": {
        "id": "NZr0JA4uOmsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the model requires a longer training time, I save the model to my cloud storage after each epoch."
      ],
      "metadata": {
        "id": "ugfpN3QjhD58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_PATH = '/content/drive/MyDrive/Colab_Checkpoints/Emotion_Model'\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "print(f\"ÂÑ≤Â≠òÊñº: {DRIVE_PATH}\")\n",
        "\n",
        "ROBERTA_BEST_MODEL_PATH = os.path.join(DRIVE_PATH, 'best_roberta_emotion_model.pth')\n",
        "DEBERTA_BEST_MODEL_PATH = os.path.join(DRIVE_PATH, 'best_deberta_emotion_model.pth')"
      ],
      "metadata": {
        "id": "HsoEjlT29X1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blocks below show how I trained the model. But in my later attempts, I directly load previously trained results."
      ],
      "metadata": {
        "id": "YZ_tVvnHDwWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1: Roberta-large"
      ],
      "metadata": {
        "id": "Z1BgMsKEFRcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start_epoch = 0\n",
        "# best_f1 = 0.0\n",
        "\n",
        "# if os.path.exists(CHECKPOINT_PATH):\n",
        "#     print(f\"\\nÂæû '{CHECKPOINT_PATH}' ÊÅ¢Âæ©...\")\n",
        "\n",
        "#     try:\n",
        "#         checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#         scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "#         start_epoch = checkpoint['epoch'] + 1\n",
        "#         best_f1 = checkpoint['best_f1']\n",
        "\n",
        "#         print(f\"Âæû Epoch {start_epoch + 1}/{EPOCHS} ÈñãÂßãË®ìÁ∑¥ (‰∏äÊ¨°ÊúÄ‰Ω≥ F1: {best_f1:.4f})„ÄÇ\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"ÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥„ÄÇ\")\n",
        "#         start_epoch = 0\n",
        "#         best_f1 = 0.0\n",
        "# else:\n",
        "#     print(\"\\nÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥„ÄÇ\")"
      ],
      "metadata": {
        "id": "bJfKCB07-IIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(start_epoch, EPOCHS):\n",
        "#     print(f\"\\n--- Epoch {epoch + 1}/{EPOCHS} ---\")\n",
        "\n",
        "#     # Ë®ìÁ∑¥ÈöéÊÆµ\n",
        "#     train_loss = train_epoch(\n",
        "#         model,\n",
        "#         train_dataloader,\n",
        "#         optimizer,\n",
        "#         criterion,\n",
        "#         device,\n",
        "#         scheduler,\n",
        "#         epoch + 1,\n",
        "#         EPOCHS\n",
        "#     )\n",
        "#     print(f\"Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "#     # È©óË≠âÈöéÊÆµ\n",
        "#     current_f1 = evaluate(model, val_dataloader, device, description=f\"È©óË≠â Epoch {epoch + 1}\")\n",
        "\n",
        "#     # ÂÑ≤Â≠ò\n",
        "#     checkpoint_state = {\n",
        "#         'epoch': epoch,\n",
        "#         'best_f1': best_f1,\n",
        "#         'model_state_dict': model.state_dict(),\n",
        "#         'optimizer_state_dict': optimizer.state_dict(),\n",
        "#         'scheduler_state_dict': scheduler.state_dict(),\n",
        "#     }\n",
        "#     torch.save(checkpoint_state, CHECKPOINT_PATH)\n",
        "#     print(f\"Â∑≤ÂÑ≤Â≠òËá≥ Google Drive: '{CHECKPOINT_PATH}'\")\n",
        "\n",
        "#     if current_f1 > best_f1:\n",
        "#         best_f1 = current_f1\n",
        "#         torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "#         print(f\"**ÊúÄ‰Ω≥Ê®°ÂûãÂ∑≤ÂÑ≤Â≠òËá≥ Google Drive (F1: {best_f1:.4f})**\")"
      ],
      "metadata": {
        "id": "ikxQZOJcDvqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: DeBERTa-v3-base"
      ],
      "metadata": {
        "id": "LBNwHWF_FOtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataloader_deberta = DataLoader(EmotionDataset(train_texts, train_labels, tokenizer=deberta_tokenizer), batch_size=16, shuffle=True)\n",
        "# val_dataloader_deberta = DataLoader(EmotionDataset(val_texts, val_labels, tokenizer=deberta_tokenizer), batch_size=16)\n",
        "\n",
        "# model_deberta = DebertaV2ForSequenceClassification.from_pretrained(DEBERTA_MODEL_NAME, num_labels=num_labels)\n",
        "# model_deberta.to(device)\n",
        "\n",
        "# optimizer_deberta = AdamW(model_deberta.parameters(), lr=2e-5)\n",
        "# EPOCHS = 5\n",
        "# total_steps_deberta = len(train_dataloader_deberta) * EPOCHS\n",
        "\n",
        "# scheduler_deberta = get_linear_schedule_with_warmup(\n",
        "#     optimizer_deberta,\n",
        "#     num_warmup_steps=int(total_steps_deberta * 0.1),\n",
        "#     num_training_steps=total_steps_deberta\n",
        "# )\n",
        "\n",
        "# best_f1_deberta = -1.0\n",
        "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     print(f\"\\n--- DeBERTa Epoch {epoch + 1}/{EPOCHS} ---\")\n",
        "\n",
        "#     train_loss = train_epoch(\n",
        "#         model_deberta,\n",
        "#         train_dataloader_deberta,\n",
        "#         optimizer_deberta,\n",
        "#         criterion,\n",
        "#         device,\n",
        "#         scheduler_deberta,\n",
        "#         epoch + 1,\n",
        "#         EPOCHS\n",
        "#     )\n",
        "#     print(f\"DeBERTa Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "#     val_logits_deberta, val_labels_deberta = evaluate(model_deberta, val_dataloader_deberta, device, description=f\"DeBERTa È©óË≠â Epoch {epoch + 1}\")\n",
        "\n",
        "#     predictions = torch.argmax(val_logits_deberta, dim=1).numpy()\n",
        "#     current_f1 = f1_score(val_labels_deberta, predictions, average='macro')\n",
        "\n",
        "#     if current_f1 > best_f1_deberta:\n",
        "#         best_f1_deberta = current_f1\n",
        "#         torch.save(model_deberta.state_dict(), DEBERTA_BEST_MODEL_PATH)\n",
        "#         print(f\"**Macro F1: {best_f1_deberta:.4f}. Â∑≤ÂÑ≤Â≠òËá≥: '{DEBERTA_BEST_MODEL_PATH}'**\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "g5gE_cmUN61X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ensemble"
      ],
      "metadata": {
        "id": "dJIWlS-QFfzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_roberta = RobertaForSequenceClassification.from_pretrained(ROBERTA_MODEL_NAME, num_labels=num_labels)\n",
        "model_deberta = DebertaV2ForSequenceClassification.from_pretrained(DEBERTA_MODEL_NAME, num_labels=num_labels)\n",
        "\n",
        "model_roberta.to(device)\n",
        "model_deberta.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dMDIYQDMFi8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(ROBERTA_BEST_MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"Êâæ‰∏çÂà∞ RoBERTa Ê®°ÂûãÊ™îÊ°à: {ROBERTA_BEST_MODEL_PATH}\")\n",
        "model_roberta.load_state_dict(torch.load(ROBERTA_BEST_MODEL_PATH, map_location=device))\n",
        "print(f\"from: {ROBERTA_BEST_MODEL_PATH}\")\n",
        "\n",
        "# ËºâÂÖ• DeBERTa Ê¨äÈáç\n",
        "if not os.path.exists(DEBERTA_BEST_MODEL_PATH):\n",
        "    print(f\"Êâæ‰∏çÂà∞ DeBERTa Ê®°ÂûãÊ™îÊ°à: {DEBERTA_BEST_MODEL_PATH}\")\n",
        "else:\n",
        "    model_deberta.load_state_dict(torch.load(DEBERTA_BEST_MODEL_PATH, map_location=device))\n",
        "    print(f\"from: {DEBERTA_BEST_MODEL_PATH}\")"
      ],
      "metadata": {
        "id": "1Wdv9lWvFm6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_ROBERTA_LOGITS, val_true_labels = evaluate(model_roberta, val_dataloader_roberta, device, description=\"RoBERTa È©óË≠â Logits\")\n",
        "VAL_DEBERTA_LOGITS, _ = evaluate(model_deberta, val_dataloader_deberta, device, description=\"DeBERTa È©óË≠â Logits\")\n",
        "ENSEMBLE_WEIGHT_VAL = 0.5\n",
        "VAL_ENSEMBLE_LOGITS = (VAL_ROBERTA_LOGITS * ENSEMBLE_WEIGHT_VAL) + (VAL_DEBERTA_LOGITS * (1 - ENSEMBLE_WEIGHT_VAL))\n",
        "print(f\"Ensemble ÂÆåÊàê: RoBERTa ({ENSEMBLE_WEIGHT_VAL:.1f}) + DeBERTa ({(1 - ENSEMBLE_WEIGHT_VAL):.1f})\")"
      ],
      "metadata": {
        "id": "ujnNTvyqFuYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_biases, best_f1_val = find_optimal_thresholds(\n",
        "    VAL_ENSEMBLE_LOGITS,\n",
        "    val_true_labels,\n",
        "    num_labels\n",
        ")"
      ],
      "metadata": {
        "id": "xfokPyHiGaYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 Logits\n",
        "ROBERTA_LOGITS = predict_single_model(model_roberta, test_dataloader_roberta, device, description=\"RoBERTa ÂñÆÊ¨°Êé®Ë´ñ\")\n",
        "\n",
        "# Model 2 Logits\n",
        "DEBERTA_LOGITS = predict_single_model(model_deberta, test_dataloader_deberta, device, description=\"DeBERTa ÂñÆÊ¨°Êé®Ë´ñ\")\n",
        "\n",
        "# Logit Averaging (Ensemble)\n",
        "ENSEMBLE_WEIGHT = 0.5\n",
        "ENSEMBLE_LOGITS = (ROBERTA_LOGITS * ENSEMBLE_WEIGHT) + (DEBERTA_LOGITS * (1 - ENSEMBLE_WEIGHT))"
      ],
      "metadata": {
        "id": "k52xEWNcGg3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_indices = predict_with_thresholds(ENSEMBLE_LOGITS, optimal_biases)\n",
        "\n",
        "test_predictions_emotions = label_encoder.inverse_transform(test_predictions_indices)\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'emotion': test_predictions_emotions\n",
        "})\n",
        "\n",
        "SUBMISSION_FILE_PATH = 'ensemble_roberta_deberta.csv'\n",
        "submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)"
      ],
      "metadata": {
        "id": "e6EseDQTGwMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}